{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Activation, AveragePooling2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'happy', 'laughing', 'nerd', 'sad', 'sick', 'surprised', 'yawning']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classes = os.listdir(\"data\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input is 150x150x3\n",
    "model.add(Conv2D(128, (11, 11), input_shape=(300, 300, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear up images so if it cannot open remove it\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "for i in classes:\n",
    "    for j in os.listdir(\"data/\"+i):\n",
    "        try:\n",
    "            Image.open(\"data/\"+i+\"/\"+j)\n",
    "        except:\n",
    "            os.remove(\"data/\"+i+\"/\"+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "happy\n",
      "laughing\n",
      "nerd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adoma\\miniconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "sick\n",
      "surprised\n",
      "Error loading image\n",
      "yawning\n"
     ]
    }
   ],
   "source": [
    "# load data where each folder has a bunch of images and the label is the folder name\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for folder in classes:\n",
    "    print(folder)\n",
    "    images = os.listdir(\"data/\" + folder)\n",
    "    for image in images:\n",
    "        try:\n",
    "            img = Image.open(\"data/\" + folder + \"/\" + image)\n",
    "            # remove alpha channel\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((300, 300))\n",
    "            img = np.array(img)\n",
    "            data.append(img)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[classes.index(folder)] = 1\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1788, 300, 300, 3)\n",
      "(1788, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 37s 790ms/step - loss: 28.1688 - accuracy: 0.1385 - val_loss: 2.0640 - val_accuracy: 0.1788\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 11s 500ms/step - loss: 2.0480 - accuracy: 0.1860 - val_loss: 2.1116 - val_accuracy: 0.1173\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 11s 484ms/step - loss: 2.0362 - accuracy: 0.2063 - val_loss: 2.0141 - val_accuracy: 0.2123\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 11s 487ms/step - loss: 1.8990 - accuracy: 0.3077 - val_loss: 1.8894 - val_accuracy: 0.3017\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 1.6562 - accuracy: 0.4126 - val_loss: 1.6702 - val_accuracy: 0.3883\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 11s 493ms/step - loss: 1.5719 - accuracy: 0.4441 - val_loss: 1.6688 - val_accuracy: 0.3631\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 1.2583 - accuracy: 0.5650 - val_loss: 1.3740 - val_accuracy: 0.5698\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 11s 487ms/step - loss: 0.8820 - accuracy: 0.6965 - val_loss: 1.2276 - val_accuracy: 0.6536\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 11s 484ms/step - loss: 0.6114 - accuracy: 0.8175 - val_loss: 1.0445 - val_accuracy: 0.7039\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 0.4258 - accuracy: 0.8713 - val_loss: 0.9662 - val_accuracy: 0.7598\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 11s 485ms/step - loss: 0.2484 - accuracy: 0.9245 - val_loss: 1.2199 - val_accuracy: 0.7905\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 11s 485ms/step - loss: 0.2272 - accuracy: 0.9406 - val_loss: 1.1668 - val_accuracy: 0.7598\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 0.1575 - accuracy: 0.9545 - val_loss: 1.0721 - val_accuracy: 0.8017\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.1333 - accuracy: 0.9601 - val_loss: 1.2841 - val_accuracy: 0.7821\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.1396 - accuracy: 0.9615 - val_loss: 1.0127 - val_accuracy: 0.8045\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.1026 - accuracy: 0.9692 - val_loss: 0.9560 - val_accuracy: 0.8101\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 11s 494ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 1.3006 - val_accuracy: 0.7933\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0705 - accuracy: 0.9839 - val_loss: 1.1065 - val_accuracy: 0.7905\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 1.4010 - val_accuracy: 0.8045\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 11s 485ms/step - loss: 0.0599 - accuracy: 0.9846 - val_loss: 1.2162 - val_accuracy: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e000850d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
